{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio\n",
    "Learn how to turn audio into text or text into audio. The Audio API provides two speech to text endpoints, transcriptions and translations, based on our state-of-the-art open source large-v2 Whisper model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transcriptions\n",
    "# Transcribe audio into whatever language the audio is in.\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file = open(\"/path/to/file/speech.mp3\", \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file, \n",
    "  # response_format=\"text\",\n",
    "  # timestamp_granularities=[\"word\"],\n",
    "  # prompt=\"ZyntriQix, Digique Plus, CynapseFive, VortiQore V8, EchoNix Array, OrbitalLink Seven, DigiFractal Matrix, PULSE, RAPT, B.R.I.C.K., Q.U.A.R.T.Z., F.L.I.N.T.\"\n",
    ")\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the response type `response_format` will be json with the raw text included.\n",
    "\n",
    "{\n",
    "  \"text\": \"Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger.\n",
    "....\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Translations\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file= open(\"/path/to/file/german.mp3\", \"rb\")\n",
    "translation = client.audio.translations.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")\n",
    "print(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refine\n",
    "\n",
    "system_prompt = \"You are a helpful assistant for the company ZyntriQix. Your task is to correct any spelling discrepancies in the transcribed text. Make sure that the names of the following products are spelled correctly: ZyntriQix, Digique Plus, CynapseFive, VortiQore V8, EchoNix Array, OrbitalLink Seven, DigiFractal Matrix, PULSE, RAPT, B.R.I.C.K., Q.U.A.R.T.Z., F.L.I.N.T. Only add necessary punctuation such as periods, commas, and capitalization, and use only the context provided.\"\n",
    "\n",
    "def generate_corrected_transcript(temperature, system_prompt, audio_file):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": transcribe(audio_file, \"\")\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "corrected_text = generate_corrected_transcript(0, system_prompt, fake_company_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "speech_file_path = Path(__file__).parent / \"speech.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"alloy\",\n",
    "  input=\"Today is a wonderful day to build something people love!\"\n",
    ")\n",
    "\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Streaming real time audio\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=\"Hello world! This is a streaming test.\",\n",
    ")\n",
    "\n",
    "response.stream_to_file(\"output.mp3\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
